{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjRBgyydKM+IU+nirEJihw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ColeTKrause/MAT421/blob/main/ModuleF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numerical Differentiation\n",
        "\n",
        "### References\n",
        "**Chapter 20: Python Numerical Methods** \\\n",
        "https://pythonnumericalmethods.berkeley.edu/notebooks/chapter20.01-Numerical-Differentiation-Problem-Statement.html"
      ],
      "metadata": {
        "id": "Asnl4exwRg58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement\n",
        "### Section 20.1\n",
        "\n",
        "**Numerical Differentiation** is the process of determining a numerical value of a function's derivative for at a specified point and serves as a tool for programmers that need to approximate the derivative of $f$. For a standard single input, single output function $f(x)$ a numerical grid is used to determine a set of evenly spaced points over some desired interval. It is important to note here creating a **numerical grid** with evenly spaced points will result in **discretizing** the function representation. \\\n",
        "\\\n",
        "**Numerical Grid mathematically:** for a given point $j$ in a numerical grid $x_{j-1},...,x_{j-n}$ are points to the left of $x_j$ and $x_{j+1},..,x_{j+n}$ are points to the right of $x_j$ with equal step sizes of $h$\\\n",
        "\\\n",
        "**Why use numerical differentiation when an analytic solution can be found for any derivative?** \\\n",
        "While mathematicians can determine the analytic solution for any differentiable function, this is not efficient or even possible sometimes in computation. Furthermore, if determining the derivative incurs heavy computational cost, it may not be applicable to the problem at hand. For instance autonomous vehicles and computer vision engineers write programs to calculate velocity and acceleration from changes in position. For the autonomous vehicle to opperate safely, they need to be able to analyze data and make decisions quickly to avoid dangerous situations like an obstacle blocking the road. If calculating the velocity takes multiple seconds, even if exact, the autonomous vehicle will not be able to respond to the danger in time."
      ],
      "metadata": {
        "id": "-gdI3Ur_TMd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finite Difference Approximating Derivatives\n",
        "### Section 20.1\n",
        "\n",
        "Recall: To determine th derivative of a function $f(x)$ at a given point $x=a$, the definition of a derivative is: \\\n",
        "$f'(a)=lim_{x → a}\\frac{f(x)-f(a)}{x-a}$ \\\n",
        "However, this formula determines the exact or analytical solution and this could cost inifinite iterations as $x$ approaches $a$. \\\n",
        "\\\n",
        "**Finite Difference** is an approach to provide an approximation by using values in the neighborhood of $x=a$. **Forward difference** is the approach by using values in the neighborhood to the right of $x_j$. **Backward difference** is an approach by using values in the neighborhood to the left of $x_j$. **Central difference** provides an esimate by using points to the left and the right of $x_j$\\\n",
        "\\\n",
        "**Forward difference:** $f'(x_j)=\\frac{f(x_{j+1})-f(x_j)}{x_{j+1}-x_j}$ \\\n",
        "\\\n",
        "**Backward difference:** $f'(x_j)=\\frac{f(x_j)-f(x_{j-1})}{x_j - x_{j-1}}$ \\\n",
        "\\\n",
        "**Central difference:** $f'(x_j)=\\frac{f(x_{j+1})-f(x_{j-1})}{x_{j+1} - x_{j-1}}$ \\\n",
        "\\\n",
        "**Taylor Series Approximations:** Is another approach to determine a Finite Difference Approximation. For the sake of brevity, observe below:\n",
        "\n",
        "\\\n",
        "**Taylor series:** $f(x)=\\frac{f(x_j)(x-x_j)^0}{0!}+\\frac{f'(x_j)(x-x_j)^1}{1!}+\\frac{f''(x_j)(x-x_j)^2}{2!}+\\frac{f'''(x_j)(x-x_j)^3}{3!}+...$ \\\n",
        "\\\n",
        "let $h=x_{j+1}-x_j$ and $0(h)=h(α+ϵ(h))=- \\frac{f''(x_j)(x-x_j)^2}{2!}-\\frac{f'''(x_j)(x-x_j)^3}{3!}$ with $O(h^p)=h^p(\\alpha + \\epsilon (h))$. The resulting difference formulas become: \\\n",
        "**Forward difference (T):** $f'(x_j)=\\frac{f(x_{j+1})-f(x_j)}{h}$, $O(h)$ \\\n",
        "\\\n",
        "**Backward difference (T):** $f'(x_j)=\\frac{f(x_j)-f(x_{j-1})}{h}$, $O(h)$ \\\n",
        "\\\n",
        "**Central difference (T):** $f'(x_j)=\\frac{f(x_{j+1})-f(x_{j-1})}{2h}$, $O(h^2)$ \\\n",
        "\\\n",
        "Anlyzing the term reveals $O(h)$ describes the **accuracy** and $O(h^p)$ reveals the **order**. As it follows that as $h$ approaches zero the accuracy improves and as order increases the speed of which the approximation approaches the true value increases. The central difference reveals accuracy increases for symmetric points arround $x_j$ compared to asymetric approaches like forward difference and backward difference. \\\n",
        "\n",
        "The accuracy of approximations can be increase simply by taking more points in the neighborhood of $x_j$ such as $x_{j-2}, x_{j-1}, x_{j+1}, x_{j+2}$ resulting in: \\\n",
        "$f'(x_j)=\\frac{f(x_{j-2})-8f(x_{j-1})+8f(x_{j+1})-f(x_{j+2})}{12h}+O(h^4)$ \\\n",
        "The increase in accuracy will come at a cost of increased computation. \\\n",
        "\\\n",
        "Python examples below:"
      ],
      "metadata": {
        "id": "1OqtMVjle5Dv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6HYPIMlRf--"
      },
      "outputs": [],
      "source": [
        "# necessary imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zInAmCt0qps5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}